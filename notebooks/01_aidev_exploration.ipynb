{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDev Dataset Exploration: AI Teammates in Software Engineering\n",
    "\n",
    "This notebook explores the AIDev dataset from SAILResearch/AI_Teammates_in_SE3, focusing on understanding how AI coding agents interact with human reviewers in real-world software development.\n",
    "\n",
    "## Dataset Overview\n",
    "- **456,535 AI-generated Pull Requests** across 5 major AI agents\n",
    "- **61,453 repositories** and **47,303 developers**\n",
    "- **Complete review histories** including human-AI collaboration patterns\n",
    "\n",
    "## Research Questions\n",
    "1. How do different AI agents perform in real-world scenarios?\n",
    "2. What are the patterns of human-AI collaboration in code review?\n",
    "3. How do review dynamics differ between AI-generated and human-generated PRs?\n",
    "4. What can we learn about the future of AI teammates in software engineering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install datasets pandas matplotlib seaborn plotly numpy scipy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üìö Libraries loaded successfully!\")\n",
    "print(f\"üêº Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load AIDev Dataset\n",
    "\n",
    "We'll load the AIDev dataset from HuggingFace. The dataset contains multiple tables that we can join for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading AIDev dataset from HuggingFace...\")\n",
    "print(\"This may take a few minutes for the first load.\")\n",
    "\n",
    "try:\n",
    "    # Load main tables using pandas with HuggingFace datasets\n",
    "    # Note: You may need to authenticate with HuggingFace if the dataset requires it\n",
    "    \n",
    "    # Core tables\n",
    "    print(\"üìÑ Loading pull requests...\")\n",
    "    pull_requests_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_pull_request.parquet\")\n",
    "    \n",
    "    print(\"üè¢ Loading repositories...\")\n",
    "    repositories_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_repository.parquet\")\n",
    "    \n",
    "    print(\"üë• Loading users...\")\n",
    "    users_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_user.parquet\")\n",
    "    \n",
    "    print(\"‚úÖ Core tables loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    print(\"\\nüí° You may need to:\")\n",
    "    print(\"1. Install datasets: pip install datasets\")\n",
    "    print(\"2. Login to HuggingFace: huggingface-cli login\")\n",
    "    print(\"3. Request access to the dataset if it's gated\")\n",
    "    \n",
    "    # Fallback: create sample data for demonstration\n",
    "    print(\"\\nüîÑ Creating sample data for demonstration...\")\n",
    "    pull_requests_df = pd.DataFrame({\n",
    "        'id': range(1000),\n",
    "        'title': [f'Sample PR {i}' for i in range(1000)],\n",
    "        'agent_label': np.random.choice(['OpenAI Codex', 'GitHub Copilot', 'Devin', 'Cursor', 'Claude Code'], 1000),\n",
    "        'state': np.random.choice(['merged', 'closed', 'open'], 1000, p=[0.6, 0.3, 0.1]),\n",
    "        'created_at': pd.date_range('2025-01-01', periods=1000, freq='H')\n",
    "    })\n",
    "    \n",
    "    repositories_df = pd.DataFrame({\n",
    "        'id': range(100),\n",
    "        'name': [f'repo-{i}' for i in range(100)],\n",
    "        'language': np.random.choice(['Python', 'JavaScript', 'TypeScript', 'Java', 'Go'], 100),\n",
    "        'stars': np.random.randint(1, 10000, 100)\n",
    "    })\n",
    "    \n",
    "    users_df = pd.DataFrame({\n",
    "        'id': range(200),\n",
    "        'login': [f'user-{i}' for i in range(200)],\n",
    "        'type': np.random.choice(['User', 'Bot'], 200, p=[0.8, 0.2])\n",
    "    })\n",
    "    \n",
    "    print(\"üìä Sample data created for demonstration purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview and Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä AIDEV DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìÑ Pull Requests: {len(pull_requests_df):,}\")\n",
    "print(f\"üè¢ Repositories: {len(repositories_df):,}\")\n",
    "print(f\"üë• Users: {len(users_df):,}\")\n",
    "\n",
    "print(\"\\nüîç Pull Requests DataFrame Info:\")\n",
    "print(f\"Shape: {pull_requests_df.shape}\")\n",
    "print(f\"Columns: {list(pull_requests_df.columns)}\")\n",
    "\n",
    "print(\"\\nüìä First few rows of Pull Requests:\")\n",
    "display(pull_requests_df.head())\n",
    "\n",
    "print(\"\\nüìà Data Types:\")\n",
    "display(pull_requests_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze AI agents distribution\n",
    "if 'agent_label' in pull_requests_df.columns:\n",
    "    agent_counts = pull_requests_df['agent_label'].value_counts()\n",
    "    \n",
    "    print(\"ü§ñ AI AGENT DISTRIBUTION\")\n",
    "    print(\"=\" * 30)\n",
    "    for agent, count in agent_counts.items():\n",
    "        percentage = (count / len(pull_requests_df)) * 100\n",
    "        print(f\"{agent:15}: {count:8,} PRs ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    agent_counts.plot(kind='bar', ax=ax1, color='skyblue')\n",
    "    ax1.set_title('Pull Requests by AI Agent')\n",
    "    ax1.set_ylabel('Number of PRs')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    ax2.pie(agent_counts.values, labels=agent_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('AI Agent Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'agent_label' column not found. Exploring available columns...\")\n",
    "    print(f\"Available columns: {list(pull_requests_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Review Data Tables\n",
    "\n",
    "Now let's load the review-specific tables to understand human-AI collaboration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading review-related tables...\")\n",
    "\n",
    "try:\n",
    "    # Attempt to load review tables\n",
    "    # Note: These might be in the AIDev-pop subset or have different names\n",
    "    \n",
    "    review_tables = {}\n",
    "    \n",
    "    # Try different possible table names\n",
    "    possible_tables = [\n",
    "        'pr_reviews',\n",
    "        'pr_review_comments', \n",
    "        'pr_comments',\n",
    "        'pr_timeline',\n",
    "        'pr_commits'\n",
    "    ]\n",
    "    \n",
    "    for table_name in possible_tables:\n",
    "        try:\n",
    "            df = pd.read_parquet(f\"hf://datasets/hao-li/AIDev/{table_name}.parquet\")\n",
    "            review_tables[table_name] = df\n",
    "            print(f\"‚úÖ Loaded {table_name}: {len(df):,} rows\")\n",
    "        except:\n",
    "            try:\n",
    "                # Try with 'all_' prefix\n",
    "                df = pd.read_parquet(f\"hf://datasets/hao-li/AIDev/all_{table_name}.parquet\")\n",
    "                review_tables[table_name] = df\n",
    "                print(f\"‚úÖ Loaded all_{table_name}: {len(df):,} rows\")\n",
    "            except:\n",
    "                print(f\"‚ö†Ô∏è Could not load {table_name}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading review tables: {e}\")\n",
    "    print(\"\\nüîÑ Creating sample review data...\")\n",
    "    \n",
    "    # Create sample review data\n",
    "    sample_pr_ids = pull_requests_df['id'].sample(n=min(500, len(pull_requests_df))).tolist()\n",
    "    \n",
    "    review_tables['pr_reviews'] = pd.DataFrame({\n",
    "        'id': range(len(sample_pr_ids)),\n",
    "        'pull_request_id': sample_pr_ids,\n",
    "        'user_login': [f'reviewer-{i}' for i in range(len(sample_pr_ids))],\n",
    "        'state': np.random.choice(['approved', 'changes_requested', 'commented'], len(sample_pr_ids)),\n",
    "        'submitted_at': pd.date_range('2025-01-01', periods=len(sample_pr_ids), freq='H'),\n",
    "        'is_bot': np.random.choice([True, False], len(sample_pr_ids), p=[0.3, 0.7])\n",
    "    })\n",
    "    \n",
    "    print(f\"üìä Created sample review data: {len(review_tables['pr_reviews']):,} reviews\")\n",
    "\n",
    "print(f\"\\nüìö Available review tables: {list(review_tables.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Review Patterns Analysis\n",
    "\n",
    "Let's analyze the review patterns to understand human-AI collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pr_reviews' in review_tables:\n",
    "    reviews_df = review_tables['pr_reviews']\n",
    "    \n",
    "    print(\"üëÄ REVIEW ANALYSIS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Basic review statistics\n",
    "    print(f\"Total reviews: {len(reviews_df):,}\")\n",
    "    \n",
    "    if 'state' in reviews_df.columns:\n",
    "        print(\"\\nüìä Review states:\")\n",
    "        state_counts = reviews_df['state'].value_counts()\n",
    "        for state, count in state_counts.items():\n",
    "            percentage = (count / len(reviews_df)) * 100\n",
    "            print(f\"{state:20}: {count:6,} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Bot vs Human reviewers\n",
    "    if 'is_bot' in reviews_df.columns:\n",
    "        bot_analysis = reviews_df['is_bot'].value_counts()\n",
    "        print(\"\\nü§ñ Reviewer types:\")\n",
    "        print(f\"Human reviewers: {bot_analysis.get(False, 0):,} ({(bot_analysis.get(False, 0)/len(reviews_df)*100):5.1f}%)\")\n",
    "        print(f\"Bot reviewers:   {bot_analysis.get(True, 0):,} ({(bot_analysis.get(True, 0)/len(reviews_df)*100):5.1f}%)\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Review states\n",
    "    if 'state' in reviews_df.columns:\n",
    "        reviews_df['state'].value_counts().plot(kind='bar', ax=axes[0,0], color='lightcoral')\n",
    "        axes[0,0].set_title('Review States Distribution')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Bot vs Human\n",
    "    if 'is_bot' in reviews_df.columns:\n",
    "        bot_labels = {True: 'Bot Reviewers', False: 'Human Reviewers'}\n",
    "        bot_counts = reviews_df['is_bot'].map(bot_labels).value_counts()\n",
    "        axes[0,1].pie(bot_counts.values, labels=bot_counts.index, autopct='%1.1f%%')\n",
    "        axes[0,1].set_title('Human vs Bot Reviewers')\n",
    "    \n",
    "    # Timeline if available\n",
    "    if 'submitted_at' in reviews_df.columns:\n",
    "        reviews_df['submitted_at'] = pd.to_datetime(reviews_df['submitted_at'])\n",
    "        daily_reviews = reviews_df.groupby(reviews_df['submitted_at'].dt.date).size()\n",
    "        daily_reviews.plot(ax=axes[1,0], color='green')\n",
    "        axes[1,0].set_title('Reviews Over Time')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Review activity by hour if available\n",
    "    if 'submitted_at' in reviews_df.columns:\n",
    "        hourly_reviews = reviews_df['submitted_at'].dt.hour.value_counts().sort_index()\n",
    "        hourly_reviews.plot(kind='bar', ax=axes[1,1], color='orange')\n",
    "        axes[1,1].set_title('Review Activity by Hour')\n",
    "        axes[1,1].set_xlabel('Hour of Day')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No review data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AI Agent Performance Comparison\n",
    "\n",
    "Let's compare how different AI agents perform in terms of PR acceptance rates and review dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge PR data with reviews if possible\n",
    "if 'pr_reviews' in review_tables and 'agent_label' in pull_requests_df.columns:\n",
    "    \n",
    "    # Join PRs with reviews\n",
    "    pr_review_data = pull_requests_df.merge(\n",
    "        review_tables['pr_reviews'], \n",
    "        left_on='id', \n",
    "        right_on='pull_request_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(\"üîÑ AGENT PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # PR state analysis by agent\n",
    "    if 'state' in pull_requests_df.columns:\n",
    "        agent_performance = pull_requests_df.groupby('agent_label')['state'].value_counts(normalize=True).unstack(fill_value=0)\n",
    "        \n",
    "        print(\"\\nüìä PR Acceptance Rates by Agent:\")\n",
    "        if 'merged' in agent_performance.columns:\n",
    "            acceptance_rates = agent_performance['merged'].sort_values(ascending=False)\n",
    "            for agent, rate in acceptance_rates.items():\n",
    "                print(f\"{agent:15}: {rate:6.1%}\")\n",
    "        \n",
    "        # Visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Stacked bar chart of PR states by agent\n",
    "        agent_performance.plot(kind='bar', stacked=True, ax=ax1, \n",
    "                             color=['green', 'red', 'orange'])\n",
    "        ax1.set_title('PR States by AI Agent')\n",
    "        ax1.set_ylabel('Proportion')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        ax1.legend(title='PR State')\n",
    "        \n",
    "        # Acceptance rates comparison\n",
    "        if 'merged' in agent_performance.columns:\n",
    "            acceptance_rates.plot(kind='bar', ax=ax2, color='skyblue')\n",
    "            ax2.set_title('PR Acceptance Rates by Agent')\n",
    "            ax2.set_ylabel('Acceptance Rate')\n",
    "            ax2.tick_params(axis='x', rotation=45)\n",
    "            ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Review analysis by agent\n",
    "    if 'is_bot' in pr_review_data.columns:\n",
    "        print(\"\\nü§ñ Review Patterns by Agent:\")\n",
    "        review_by_agent = pr_review_data.groupby(['agent_label', 'is_bot']).size().unstack(fill_value=0)\n",
    "        \n",
    "        if len(review_by_agent.columns) > 0:\n",
    "            # Calculate percentages\n",
    "            review_percentages = review_by_agent.div(review_by_agent.sum(axis=1), axis=0) * 100\n",
    "            \n",
    "            print(\"Bot vs Human Review Distribution:\")\n",
    "            display(review_percentages.round(1))\n",
    "            \n",
    "            # Visualization\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            review_percentages.plot(kind='bar', ax=ax, \n",
    "                                  color=['lightblue', 'lightcoral'])\n",
    "            ax.set_title('Human vs Bot Reviews by AI Agent')\n",
    "            ax.set_ylabel('Percentage of Reviews')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(['Human Reviews', 'Bot Reviews'])\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Insufficient data for agent performance comparison\")\n",
    "    if 'agent_label' not in pull_requests_df.columns:\n",
    "        print(\"   Missing: agent_label column\")\n",
    "    if 'pr_reviews' not in review_tables:\n",
    "        print(\"   Missing: review data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Repository and Language Analysis\n",
    "\n",
    "Let's explore which programming languages and types of repositories AI agents work with most effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository analysis\n",
    "if 'language' in repositories_df.columns:\n",
    "    print(\"üíª PROGRAMMING LANGUAGE ANALYSIS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Language distribution\n",
    "    language_counts = repositories_df['language'].value_counts().head(10)\n",
    "    \n",
    "    print(\"\\nüìä Top Programming Languages:\")\n",
    "    for lang, count in language_counts.items():\n",
    "        percentage = (count / len(repositories_df)) * 100\n",
    "        print(f\"{lang:15}: {count:4,} repos ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Top languages bar chart\n",
    "    language_counts.plot(kind='bar', ax=ax1, color='purple', alpha=0.7)\n",
    "    ax1.set_title('Top Programming Languages in AIDev Dataset')\n",
    "    ax1.set_ylabel('Number of Repositories')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Repository stars distribution if available\n",
    "    if 'stars' in repositories_df.columns:\n",
    "        repositories_df['stars'].hist(bins=50, ax=ax2, color='gold', alpha=0.7)\n",
    "        ax2.set_title('Repository Popularity Distribution')\n",
    "        ax2.set_xlabel('GitHub Stars')\n",
    "        ax2.set_ylabel('Number of Repositories')\n",
    "        ax2.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Repository size and activity analysis\n",
    "if 'stars' in repositories_df.columns:\n",
    "    print(\"\\n‚≠ê Repository Popularity Statistics:\")\n",
    "    stars_stats = repositories_df['stars'].describe()\n",
    "    print(f\"Mean stars: {stars_stats['mean']:,.0f}\")\n",
    "    print(f\"Median stars: {stars_stats['50%']:,.0f}\")\n",
    "    print(f\"Max stars: {stars_stats['max']:,.0f}\")\n",
    "    \n",
    "    # Popular repositories\n",
    "    print(\"\\nüåü Most Popular Repositories:\")\n",
    "    top_repos = repositories_df.nlargest(10, 'stars')[['name', 'language', 'stars']]\n",
    "    display(top_repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Analysis\n",
    "\n",
    "Understanding how AI agent activity and review patterns evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis of PR creation\n",
    "if 'created_at' in pull_requests_df.columns:\n",
    "    print(\"üìÖ TEMPORAL ANALYSIS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Convert to datetime\n",
    "    pull_requests_df['created_at'] = pd.to_datetime(pull_requests_df['created_at'])\n",
    "    \n",
    "    # Date range\n",
    "    date_range = pull_requests_df['created_at'].agg(['min', 'max'])\n",
    "    print(f\"\\nüìä Dataset covers: {date_range['min'].strftime('%Y-%m-%d')} to {date_range['max'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total duration: {(date_range['max'] - date_range['min']).days} days\")\n",
    "    \n",
    "    # Create time-based visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Daily PR creation\n",
    "    daily_prs = pull_requests_df.groupby(pull_requests_df['created_at'].dt.date).size()\n",
    "    daily_prs.plot(ax=axes[0,0], color='blue', alpha=0.7)\n",
    "    axes[0,0].set_title('Daily PR Creation')\n",
    "    axes[0,0].set_ylabel('Number of PRs')\n",
    "    \n",
    "    # Weekly patterns\n",
    "    weekly_pattern = pull_requests_df['created_at'].dt.day_name().value_counts().reindex(\n",
    "        ['Monday', 'Tuesday', 'Wednesday', 'Thursday',
